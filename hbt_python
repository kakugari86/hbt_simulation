# hbt_analysis_template_v22_fast.py
# ------------------------------------------------------------
# Fast HBT simulator/fit: synthesize the correlation histogram
# directly (no giant time-tag arrays). Safe for long T and high rates.
# ------------------------------------------------------------

from dataclasses import dataclass
import numpy as np
import math
import json

# ---------------- Parameters ----------------
@dataclass
class SimParams:
    rate_A: float = 5e6        # singles rate [cps] for SPAD-A
    rate_B: float = 5e6        # singles rate [cps] for SPAD-B
    T: float = 1800.0          # acquisition time [s]
    epsilon: float = 1e-3      # correlation amplitude at tau=0
    sigma_tau_ps: float = 50.0 # true Gaussian sigma of g2(τ) [ps]
    window_ps: float = 1000.0  # correlation window half-range [ps]
    bin_ps: float = 20.0       # histogram bin width [ps]
    seed: int = 42             # RNG seed for reproducibility
    initial_sigma_ps: float = 50.0  # initial guess for fit

# ---------------- Fast histogram synthesis ----------------
def synthesize_histogram_fast(params: SimParams, rng=None):
    """
    Build the correlation histogram directly:
      expected baseline per bin: lam0 = R_A * R_B * T * Δt
      expected g2(τ): 1 + ε * exp(-τ^2 / (2 σ_τ^2))
      counts_k ~ Poisson(lam0 * g2(τ_k))
    Returns:
      tau_ps [nbins], counts [nbins, int64], bin_ps [ps], lam0 (baseline pairs per bin)
      N_A_exp, N_B_exp (expected singles, no arrays allocated)
    """
    if rng is None:
        rng = np.random.default_rng(params.seed)

    nbins = int(2 * params.window_ps / params.bin_ps) + 1
    # symmetric centers (0 in the middle)
    tau_ps = (np.arange(nbins) - nbins // 2) * params.bin_ps

    bin_s = params.bin_ps * 1e-12
    lam0 = params.rate_A * params.rate_B * params.T * bin_s  # baseline pairs per bin

    # expected g2(τ) shape
    g2_exp = 1.0 + params.epsilon * np.exp(-0.5 * (tau_ps / params.sigma_tau_ps) ** 2)

    # draw Poisson counts per bin (int64)
    lam = lam0 * g2_exp
    counts = rng.poisson(lam).astype(np.int64)

    N_A_exp = params.rate_A * params.T
    N_B_exp = params.rate_B * params.T
    return tau_ps, counts, params.bin_ps, lam0, N_A_exp, N_B_exp

# ---------------- Normalization ----------------
def g2_from_hist(counts, baseline_pairs_per_bin):
    """Normalize to g2 by dividing counts by baseline per bin."""
    baseline = float(baseline_pairs_per_bin)
    if baseline <= 0:
        baseline = 1.0
    return counts / baseline

# ---------------- Fitting ----------------
def fit_gaussian_peak(tau_ps, g2_vals, initial_sigma_ps=100.0, roi_ps=None):
    tau = np.asarray(tau_ps)[1:-1]   # drop edge bins
    g2  = np.asarray(g2_vals)[1:-1]

    if roi_ps is None:
        roi_ps = max(5.0 * initial_sigma_ps, 200.0)  # at least ±200 ps
    m = np.abs(tau) <= roi_ps
    tau = tau[m]; g2 = g2[m]

    if tau.size < 5:
        # fallback: widen the ROI if something went wrong
        m = np.abs(np.asarray(tau_ps)) <= (5.0 * initial_sigma_ps)
        tau = np.asarray(tau_ps)[m]; g2 = np.asarray(g2_vals)[m]

    def model(x, A, sigma):
        return 1.0 + A * np.exp(-0.5 * (x / sigma) ** 2)

    try:
        from scipy.optimize import curve_fit
        p0 = [1e-3, initial_sigma_ps]
        bounds = ([0.0,   5.0],      # A in [0, 0.05], sigma in [5, 500] ps
                  [0.05, 500.0])
        popt, pcov = curve_fit(model, tau, g2, p0=p0, bounds=bounds, maxfev=20000)
        A, sigma_ps = popt
        return {"epsilon": float(max(A, 0.0)), "sigma_ps": float(abs(sigma_ps)), "C": 1.0, "success": True}
    except Exception:
        # SciPy-less fallback: scan sigma and solve A by linear least-squares
        sigmas = np.geomspace(5.0, 500.0, 160)
        best = (initial_sigma_ps, 1e-3, np.inf)  # (sigma, A, MSE)
        for s in sigmas:
            G = np.exp(-0.5 * (tau / s) ** 2)
            denom = float(np.dot(G, G))
            if denom <= 0:
                continue
            A = float(np.dot(G, g2 - 1.0) / denom)
            if not (0.0 <= A <= 0.05):
                continue
            pred = 1.0 + A * G
            mse = float(np.mean((pred - g2) ** 2))
            if mse < best[2]:
                best = (s, A, mse)
        sigma_ps, A, _ = best
        return {"epsilon": float(max(A, 0.0)), "sigma_ps": float(abs(sigma_ps)), "C": 1.0, "success": True}

# ---------------- Utilities ----------------
def sigma_z_from_sigma_tau(sigma_tau_ps, sigma_inst_ps=0.0):
    """
    Convert temporal sigma (ps) to longitudinal bunch length sigma_z [m]:
      sigma_z = (c / sqrt(2)) * sqrt( sigma_tau^2 - sigma_inst^2 )
    where sigma_inst is the instrumental RMS (ps).
    """
    c = 299_792_458.0  # m/s
    st_ps = max(0.0, sigma_tau_ps**2 - sigma_inst_ps**2) ** 0.5
    st_s = st_ps * 1e-12
    return (c / math.sqrt(2.0)) * st_s

# ---------------- Demo ----------------
def demo_fast():
    params = SimParams(
 #       rate_A=5e6, rate_B=5e6,
        rate_A=1e7, rate_B=1e7,
#        T=1800.0,               # long acquisition (30 min)
        T=36000.0,               # long acquisition (60 min)
        epsilon=1e-3,           # small correlation amplitude (OSR-like)
        sigma_tau_ps=50.0,
        window_ps=1000.0,
        bin_ps=20.0,
        seed=123,
        initial_sigma_ps=50.0
    )

    tau_ps, counts, bin_ps, lam0, N_A_exp, N_B_exp = synthesize_histogram_fast(params)
    g2_vals = g2_from_hist(counts, lam0)

    fit = fit_gaussian_peak(
        tau_ps, g2_vals,
        initial_sigma_ps=params.initial_sigma_ps,
        roi_ps=None
    )

    sigma_z_m = sigma_z_from_sigma_tau(fit["sigma_ps"], sigma_inst_ps=0.0)
    report = {
        "N_A_expected": int(N_A_exp),
        "N_B_expected": int(N_B_exp),
        "baseline_pairs_per_bin": float(lam0),
        "fit_sigma_tau_ps": float(fit["sigma_ps"]),
        "fit_epsilon": float(fit["epsilon"]),
        "fit_C": float(fit["C"]),
        "sigma_z_m": float(sigma_z_m),
        "sigma_z_mm": float(sigma_z_m * 1e3)
    }
    return tau_ps, g2_vals, fit, report

# ---------------- Main ----------------
if __name__ == "__main__":
    tau_ps, g2_vals, fit, report = demo_fast()
    print(json.dumps(report, indent=2))

    # Optional plot (if matplotlib is available)
    try:
        import matplotlib.pyplot as plt
        plt.figure(figsize=(7.2, 4.8))
        m = np.abs(tau_ps) <= 500.0
        plt.plot(tau_ps[m], g2_vals[m], ".", ms=3, label="data")
        A = fit["epsilon"]; sigma = fit["sigma_ps"]; C = 1.0
        t = np.linspace(-500.0, 500.0, 801)
        plt.plot(t, C + A * np.exp(-0.5 * (t / sigma) ** 2), "-", label="fit")
        plt.xlabel(r"$\tau$ [ps]"); plt.ylabel(r"$g^{(2)}(\tau)$")
        plt.title("g2(τ) with rate-based normalization (fast synthesis)")
        plt.legend()
        plt.tight_layout()
        plt.savefig("g2_fast_v22.png", dpi=150)
        # plt.show()
    except Exception as e:
        print("Plot skipped:", e)
